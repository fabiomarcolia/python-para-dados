{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 — PyArrow + Parquet: schema e particionamento\n",
        "\n",
        "Objetivo: entender Parquet na prática e criar dados particionados para leitura eficiente.\n",
        "\n",
        "Tempo: ~25–30 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def find_repo_root(start: Path | None = None) -> Path:\n",
        "    \"\"\"Sobe diretórios até encontrar uma 'marca' do repositório (README.md + pasta data).\"\"\"\n",
        "    cur = (start or Path.cwd()).resolve()\n",
        "    for _ in range(10):\n",
        "        if (cur / \"README.md\").exists() and (cur / \"data\").exists():\n",
        "            return cur\n",
        "        cur = cur.parent\n",
        "    # fallback: assume cwd\n",
        "    return Path.cwd().resolve()\n",
        "\n",
        "ROOT = find_repo_root()\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "SAMPLE_DIR = DATA_DIR / \"sample\"\n",
        "\n",
        "print(\"ROOT:\", ROOT)\n",
        "print(\"SAMPLE_DIR:\", SAMPLE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Pandas → Parquet com schema controlado\n",
        "\n",
        "Vamos escrever um Parquet e inspecionar o schema com PyArrow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "df = pd.read_csv(SAMPLE_DIR / \"sales.csv\")\n",
        "\n",
        "table = pa.Table.from_pandas(df)\n",
        "table.schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Escrevendo Parquet e lendo schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "out_dir = ROOT / \"data\" / \"output\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "parquet_path = out_dir / \"sales_arrow.parquet\"\n",
        "pq.write_table(table, parquet_path)\n",
        "\n",
        "pq.read_schema(parquet_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Dataset particionado (ex.: por região)\n",
        "\n",
        "Particionar ajuda leituras seletivas (ex.: só uma região)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pyarrow.dataset as ds\n",
        "\n",
        "partition_dir = out_dir / \"sales_partitioned\"\n",
        "partition_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ds.write_dataset(\n",
        "    data=table,\n",
        "    base_dir=str(partition_dir),\n",
        "    format=\"parquet\",\n",
        "    partitioning=[\"region\"],\n",
        "    existing_data_behavior=\"overwrite_or_ignore\"\n",
        ")\n",
        "\n",
        "partition_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Lendo só uma partição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dataset = ds.dataset(str(partition_dir), format=\"parquet\")\n",
        "\n",
        "# Filtra por região sem ler tudo\n",
        "filtered = dataset.to_table(filter=ds.field(\"region\") == \"Sudeste\")\n",
        "filtered.num_rows, filtered.schema.names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercícios\n",
        "\n",
        "1- Particione por `category`.\n",
        "2- Compare o tamanho do Parquet único vs dataset particionado.\n",
        "3- Leia duas regiões e faça uma agregação em PyArrow (soma de revenue)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Escreva suas respostas aqui\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python-dados-mentoria",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}