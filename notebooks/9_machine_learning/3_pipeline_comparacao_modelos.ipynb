{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a2e955",
   "metadata": {},
   "source": [
    "# 03 — ML: pipeline + comparação de modelos\n",
    "\n",
    "Objetivo: montar um pipeline robusto e comparar modelos com validação cruzada.\n",
    "\n",
    "Tempo: ~25–30 min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a889be5",
   "metadata": {},
   "source": [
    "## O que você vai fazer\n",
    "\n",
    "1- Montar um **Pipeline** com pré-processamento (num + categórico)  \n",
    "2- Comparar modelos com validação cruzada (AUC)  \n",
    "3- Manter tudo reprodutível (mesma função, mesma base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    cur = (start or Path.cwd()).resolve()\n",
    "    for _ in range(10):\n",
    "        if (cur / \"README.md\").exists() and (cur / \"data\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "root = find_repo_root()\n",
    "DATA = root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc001a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rfm_from_sample() -> pd.DataFrame:\n",
    "    sales = pd.read_csv(DATA / \"sample\" / \"sales.csv\")\n",
    "    customers = pd.read_csv(DATA / \"sample\" / \"customers.csv\")\n",
    "    sales[\"date\"] = pd.to_datetime(sales[\"date\"])\n",
    "    customers[\"signup_date\"] = pd.to_datetime(customers[\"signup_date\"])\n",
    "\n",
    "    df = sales.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "    as_of = df[\"date\"].max() + pd.Timedelta(days=1)\n",
    "\n",
    "    rfm = (\n",
    "        df.groupby(\"customer_id\")\n",
    "          .agg(\n",
    "              last_purchase=(\"date\", \"max\"),\n",
    "              frequency=(\"order_id\", \"nunique\"),\n",
    "              monetary=(\"revenue\", \"sum\"),\n",
    "              avg_order_value=(\"revenue\", \"mean\"),\n",
    "              category_nunique=(\"category\", \"nunique\"),\n",
    "              region_nunique=(\"region\", \"nunique\"),\n",
    "              segment=(\"segment\", \"first\"),\n",
    "              signup_date=(\"signup_date\", \"first\"),\n",
    "          )\n",
    "          .reset_index()\n",
    "    )\n",
    "    rfm[\"recency_days\"] = (as_of - rfm[\"last_purchase\"]).dt.days\n",
    "\n",
    "    threshold = rfm[\"monetary\"].quantile(0.80)\n",
    "    rfm[\"is_vip\"] = (rfm[\"monetary\"] >= threshold).astype(int)\n",
    "\n",
    "    # salva para reuso\n",
    "    out_dir = DATA / \"processed\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rfm.to_parquet(out_dir / \"rfm_features.parquet\", index=False)\n",
    "\n",
    "    return rfm\n",
    "\n",
    "def load_rfm() -> pd.DataFrame:\n",
    "    path = DATA / \"processed\" / \"rfm_features.parquet\"\n",
    "    if path.exists():\n",
    "        return pd.read_parquet(path)\n",
    "    return build_rfm_from_sample()\n",
    "\n",
    "rfm = load_rfm()\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f446ea",
   "metadata": {},
   "source": [
    "## Features numéricas + categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"is_vip\"\n",
    "num_features = [\"recency_days\", \"frequency\", \"monetary\", \"avg_order_value\", \"category_nunique\", \"region_nunique\"]\n",
    "cat_features = [\"segment\"]\n",
    "\n",
    "X = rfm[num_features + cat_features].copy()\n",
    "y = rfm[target].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168f753",
   "metadata": {},
   "source": [
    "## Pipeline com ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71123ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"scaler\", StandardScaler())]), num_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238ad2f",
   "metadata": {},
   "source": [
    "## Comparando modelos (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=400, class_weight=\"balanced\", random_state=42),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=300, random_state=42, class_weight=\"balanced\"),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"model\", clf)])\n",
    "    aucs = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "    scores.append({\"model\": name, \"auc_mean\": aucs.mean(), \"auc_std\": aucs.std()})\n",
    "\n",
    "scores_df = pd.DataFrame(scores).sort_values(\"auc_mean\", ascending=False)\n",
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b1222",
   "metadata": {},
   "source": [
    "## Treinando o melhor e avaliando no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = scores_df.iloc[0][\"model\"]\n",
    "best_model = models[best_name]\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"model\", best_model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Best:\", best_name)\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, proba).round(4))\n",
    "print(classification_report(y_test, pred))\n",
    "RocCurveDisplay.from_predictions(y_test, proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df487f",
   "metadata": {},
   "source": [
    "## Salvando artefatos do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c861088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "\n",
    "out_dir = DATA / \"output\" / \"ml\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(pipe, out_dir / \"model_pipeline_best.joblib\")\n",
    "(out_dir / \"scores_cv.json\").write_text(json.dumps(scores, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Salvo:\", out_dir / \"model_pipeline_best.joblib\")\n",
    "print(\"Salvo:\", out_dir / \"scores_cv.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1b698",
   "metadata": {},
   "source": [
    "## Exercícios (10–15 min)\n",
    "\n",
    "1- Adicione um terceiro modelo: `GradientBoostingClassifier`.  \n",
    "2- Troque scoring por `average_precision` e compare.  \n",
    "3- Plote a distribuição das probabilidades (`proba`) por classe real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
