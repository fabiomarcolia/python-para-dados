{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 — Exceções, validação e logging (padrão de projeto)\n",
        "\n",
        "Objetivo: tratar erros do jeito certo em pipelines/análises e deixar rastros (logs).\n",
        "\n",
        "Tempo: ~20–30 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def find_repo_root(start: Path | None = None) -> Path:\n",
        "    \"\"\"Sobe diretórios até encontrar uma 'marca' do repositório (README.md + pasta data).\"\"\"\n",
        "    cur = (start or Path.cwd()).resolve()\n",
        "    for _ in range(10):\n",
        "        if (cur / \"README.md\").exists() and (cur / \"data\").exists():\n",
        "            return cur\n",
        "        cur = cur.parent\n",
        "    # fallback: assume cwd\n",
        "    return Path.cwd().resolve()\n",
        "\n",
        "ROOT = find_repo_root()\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "SAMPLE_DIR = DATA_DIR / \"sample\"\n",
        "\n",
        "print(\"ROOT:\", ROOT)\n",
        "print(\"SAMPLE_DIR:\", SAMPLE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Erros comuns em dados\n",
        "\n",
        "- arquivo não existe\n",
        "- coluna esperada não existe\n",
        "- tipo errado (string onde deveria ser número)\n",
        "\n",
        "A ideia aqui é falhar *rápido* e com mensagem útil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_sales(path):\n",
        "    # Comentário importante: sempre valide o caminho antes de ler\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Arquivo não encontrado: {path}\")\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Validação mínima de esquema\n",
        "    required = {\"date\",\"region\",\"category\",\"revenue\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Colunas faltando: {sorted(missing)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "sales = load_sales(SAMPLE_DIR / \"sales.csv\")\n",
        "sales.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Logging\n",
        "\n",
        "Use `logging` (não `print`) quando você quer histórico e debug mais fácil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger(\"mentoria\")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Em notebooks, pode rolar duplicação de handlers; por isso o guard:\n",
        "if not logger.handlers:\n",
        "    handler = logging.StreamHandler()\n",
        "    fmt = logging.Formatter(\"[%(levelname)s] %(message)s\")\n",
        "    handler.setFormatter(fmt)\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "logger.info(\"Carregando sales.csv...\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def safe_load_sales(path):\n",
        "    try:\n",
        "        df = load_sales(path)\n",
        "        logger.info(\"OK: %s linhas, %s colunas\", len(df), len(df.columns))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        # Dica: em projetos reais, você pode logar stacktrace com logger.exception(...)\n",
        "        logger.error(\"Falhou ao carregar: %s\", e)\n",
        "        return None\n",
        "\n",
        "_ = safe_load_sales(SAMPLE_DIR / \"sales.csv\")\n",
        "_ = safe_load_sales(SAMPLE_DIR / \"nao_existe.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Validação simples (antes de analisar)\n",
        "\n",
        "Mini-checklist: nulos, tipos, duplicatas, faixas esperadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = sales.copy()\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "\n",
        "checks = {\n",
        "    \"nulos_total\": int(df.isna().sum().sum()),\n",
        "    \"duplicadas_order_id\": int(df.duplicated(\"order_id\").sum()),\n",
        "    \"revenue_negativa\": int((df[\"revenue\"] < 0).sum()),\n",
        "    \"datas_invalidas\": int(df[\"date\"].isna().sum()),\n",
        "}\n",
        "\n",
        "checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercícios\n",
        "\n",
        "1- Crie uma função `validate_positive(df, col)` que levanta erro se houver valores <= 0.\n",
        "2- Faça `logger.exception(...)` dentro do except para capturar stacktrace.\n",
        "3- Monte um dicionário `report` com 5 validações e salve em JSON."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Escreva suas respostas aqui\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python-dados-mentoria",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}