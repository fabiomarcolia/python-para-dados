{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e4cf2b",
   "metadata": {},
   "source": [
    "# Mini-projeto 06 — PyArrow & Parquet\n",
    "\n",
    "Persistência eficiente: parquet e particionamento.\n",
    "\n",
    "> Entregável de portfólio — gerado em 2026-01-30.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e42dd",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "        Escrever e ler Parquet com PyArrow e criar um dataset particionado por `region`.\n",
    "\n",
    "        ## Entregáveis (para portfólio)\n",
    "\n",
    "        - [ ] `outputs/sales.parquet`\n",
    "- [ ] `outputs/sales_ds/` (particionado)\n",
    "- [ ] `reports/parquet_notes.md`\n",
    "\n",
    "        ## Como usar\n",
    "\n",
    "        1- Rode este notebook (kernel com o `.venv` do repo)  \n",
    "        2- Gere **assets** (imagens/HTML) e **reports** (markdown/json) dentro desta pasta  \n",
    "        3- Faça commit dos arquivos gerados para evidenciar o resultado no GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: detectar raiz do repositório + paths padrão\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    for _ in range(12):\n",
    "        if (p / \"requirements.txt\").exists() and (p / \"README.md\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return (start or Path.cwd()).resolve()\n",
    "\n",
    "ROOT = find_repo_root()\n",
    "DATA_SAMPLE = ROOT / \"data\" / \"sample\"\n",
    "DATA_SOURCE = ROOT / \"data\" / \"source\" / \"bases-dados-analytics-powerbi-ml\"\n",
    "\n",
    "# Pasta do projeto (onde salvar assets/outputs/reports)\n",
    "PROJ = ROOT / \"projects\" / \"06_pyarrow_parquet\"\n",
    "ASSETS = PROJ / \"assets\"\n",
    "OUTPUTS = PROJ / \"outputs\"\n",
    "REPORTS = PROJ / \"reports\"\n",
    "for d in (ASSETS, OUTPUTS, REPORTS):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset padrão (sempre disponível)\n",
    "sales_path = DATA_SAMPLE / \"sales.csv\"\n",
    "customers_path = DATA_SAMPLE / \"customers.csv\"\n",
    "sales = pd.read_csv(sales_path, parse_dates=[\"date\"])\n",
    "customers = pd.read_csv(customers_path, parse_dates=[\"signup_date\"])\n",
    "\n",
    "# Dataset real (opcional): se você adicionou o submodule/clone em dados/source/\n",
    "has_real = DATA_SOURCE.exists()\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Dataset sample:\", sales.shape, customers.shape)\n",
    "print(\"Dataset real disponível?\", has_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8746c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# DataFrame -> Arrow Table\n",
    "table = pa.Table.from_pandas(sales)\n",
    "\n",
    "out_file = OUTPUTS / \"sales.parquet\"\n",
    "pq.write_table(table, out_file)\n",
    "print(\"Salvo:\", out_file)\n",
    "\n",
    "# Dataset particionado\n",
    "out_ds = OUTPUTS / \"sales_ds\"\n",
    "pq.write_to_dataset(table, root_path=str(out_ds), partition_cols=[\"region\"])\n",
    "print(\"Dataset particionado em:\", out_ds)\n",
    "\n",
    "# Ler de volta via dataset (scan)\n",
    "dataset = ds.dataset(str(out_ds), format=\"parquet\")\n",
    "# Filtrar uma região\n",
    "sudeste = dataset.to_table(filter=ds.field(\"region\") == \"Sudeste\").to_pandas()\n",
    "display(sudeste.head())\n",
    "\n",
    "md = []\n",
    "md.append(\"# Notas Parquet — 06_pyarrow_parquet\\n\")\n",
    "md.append(\"- Parquet melhora leitura/armazenamento em datasets tabulares\\n\")\n",
    "md.append(\"- Particionar ajuda em filtros (pruning)\\n\")\n",
    "md.append(f\"- Exemplo: Sudeste linhas = {len(sudeste)}\\n\")\n",
    "out = REPORTS / \"parquet_notes.md\"\n",
    "out.write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "print(\"Salvo:\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
