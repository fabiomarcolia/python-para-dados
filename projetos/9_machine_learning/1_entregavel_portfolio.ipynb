{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8ea700",
   "metadata": {},
   "source": [
    "# Mini-projeto 08 — ML baseline\n",
    "\n",
    "Classificar segmento (B2B vs B2C) a partir de comportamento de compra.\n",
    "\n",
    "> Entregável de portfólio — gerado em 2026-01-30.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbe0cb",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "        Criar features por cliente, treinar um baseline com scikit-learn e salvar métricas + artefatos.\n",
    "\n",
    "        ## Entregáveis (para portfólio)\n",
    "\n",
    "        - [ ] `reports/ml_metrics.json`\n",
    "- [ ] `assets/confusion_matrix.png`\n",
    "- [ ] `outputs/model.joblib`\n",
    "\n",
    "        ## Como usar\n",
    "\n",
    "        1- Rode este notebook (kernel com o `.venv` do repo)  \n",
    "        2- Gere **assets** (imagens/HTML) e **reports** (markdown/json) dentro desta pasta  \n",
    "        3- Faça commit dos arquivos gerados para evidenciar o resultado no GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee33a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: detectar raiz do repositório + paths padrão\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    for _ in range(12):\n",
    "        if (p / \"requirements.txt\").exists() and (p / \"README.md\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return (start or Path.cwd()).resolve()\n",
    "\n",
    "ROOT = find_repo_root()\n",
    "DATA_SAMPLE = ROOT / \"data\" / \"sample\"\n",
    "DATA_SOURCE = ROOT / \"data\" / \"source\" / \"bases-dados-analytics-powerbi-ml\"\n",
    "\n",
    "# Pasta do projeto (onde salvar assets/outputs/reports)\n",
    "PROJ = ROOT / \"projects\" / \"08_machine_learning\"\n",
    "ASSETS = PROJ / \"assets\"\n",
    "OUTPUTS = PROJ / \"outputs\"\n",
    "REPORTS = PROJ / \"reports\"\n",
    "for d in (ASSETS, OUTPUTS, REPORTS):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset padrão (sempre disponível)\n",
    "sales_path = DATA_SAMPLE / \"sales.csv\"\n",
    "customers_path = DATA_SAMPLE / \"customers.csv\"\n",
    "sales = pd.read_csv(sales_path, parse_dates=[\"date\"])\n",
    "customers = pd.read_csv(customers_path, parse_dates=[\"signup_date\"])\n",
    "\n",
    "# Dataset real (opcional): se você adicionou o submodule/clone em dados/source/\n",
    "has_real = DATA_SOURCE.exists()\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Dataset sample:\", sales.shape, customers.shape)\n",
    "print(\"Dataset real disponível?\", has_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267af508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# 1) Features por cliente (comportamento)\n",
    "df = sales.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "feats = (\n",
    "    df.groupby([\"customer_id\", \"segment\"])\n",
    "    .agg(\n",
    "        orders=(\"order_id\", \"nunique\"),\n",
    "        qty=(\"qty\", \"sum\"),\n",
    "        revenue=(\"revenue\", \"sum\"),\n",
    "        avg_ticket=(\"revenue\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 2) X/y\n",
    "X = feats[[\"orders\", \"qty\", \"revenue\", \"avg_ticket\"]]\n",
    "y = feats[\"segment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# 3) Pipeline baseline\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000)),\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# 4) Métricas\n",
    "report_txt = classification_report(y_test, pred, output_dict=False)\n",
    "print(report_txt)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred, labels=sorted(y.unique()))\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks(range(cm.shape[1]), sorted(y.unique()))\n",
    "plt.yticks(range(cm.shape[0]), sorted(y.unique()))\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "out_img = ASSETS / \"confusion_matrix.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_img, dpi=160)\n",
    "plt.close()\n",
    "print(\"Salvo:\", out_img)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": float(acc),\n",
    "    \"n_train\": int(len(X_train)),\n",
    "    \"n_test\": int(len(X_test)),\n",
    "    \"features\": list(X.columns),\n",
    "}\n",
    "out_metrics = REPORTS / \"ml_metrics.json\"\n",
    "out_metrics.write_text(json.dumps(metrics, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"Salvo:\", out_metrics)\n",
    "\n",
    "# 5) Salvar modelo\n",
    "out_model = OUTPUTS / \"model.joblib\"\n",
    "joblib.dump(pipe, out_model)\n",
    "print(\"Salvo:\", out_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1090d",
   "metadata": {},
   "source": [
    "## Evidências\n",
    "\n",
    "![](./assets/confusion_matrix.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
